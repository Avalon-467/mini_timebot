# === LLM API 配置（支持 DeepSeek / OpenAI / Gemini 等 OpenAI 兼容接口）===
LLM_API_KEY=your_api_key_here
LLM_BASE_URL=https://api.deepseek.com/v1
LLM_MODEL=deepseek-chat
# 是否支持图片识别（vision），DeepSeek 设为 false，Gemini/GPT-4o 设为 true
LLM_VISION_SUPPORT=false

# === 端口配置（可选，以下为默认值，一般无需修改）===
PORT_SCHEDULER=51201
PORT_AGENT=51200
PORT_FRONTEND=51209

# === 指令执行模块配置（可选，以下为默认值）===
# 命令白名单，逗号分隔。留空或不设置则使用内置默认白名单
# ALLOWED_COMMANDS=ls,cat,head,tail,wc,du,find,file,stat,grep,awk,sed,sort,uniq,cut,tr,diff,comm,echo,date,cal,whoami,uname,hostname,uptime,free,df,env,printenv,pwd,which,expr,seq,yes,true,false,base64,md5sum,sha256sum,xxd,python,python3,ping,curl,wget
# 命令执行超时（秒）
# EXEC_TIMEOUT=30
# 输出最大字符数
# MAX_OUTPUT_LENGTH=8000

# === OASIS 论坛服务配置（可选，以下为默认值）===
PORT_OASIS=51202
OASIS_BASE_URL=http://127.0.0.1:51202

# === Bark 推送服务配置（可选）===
# Bark Server 监听端口
PORT_BARK=58010
# 以下两项由 tunnel.py 自动写入，无需手动配置
# PUBLIC_DOMAIN=https://xxx.trycloudflare.com
# BARK_PUBLIC_URL=https://xxx.trycloudflare.com

# === 内部服务通信密钥（可选）===
# 保护 /system_trigger、/oasis/ask、/_internal/oasis_response 等内部端点
# 留空则 mainagent 首次启动时自动生成并写入 .env
# INTERNAL_TOKEN=
